Base Header Level:  3
latex input:        document-info
latex footer:       x3-notes-end

# Regular Languages
A language is regular if and only if it is recognized by a DFA, NFA, or Regexp.

Note: **ALL FINITE LANGUAGES ARE REGULAR**

**DFA** \\(M = (Q, \Sigma, \delta, R, q_0 \in Q, F \subseteq Q)\\)

**NFA** DFA but with epsilon transitions. DFA equivalent: each dfa state represents some subset of NFA states.

## Regular Expressions
A regexp over \\(\Sigma\\) is one of \\(a\in \Sigma,\epsilon,\emptyset,(R_1\cup R_2),(R_1\circ R_2),R_1^* \\) where each \\(R_i\\) is a regexp.

**Closure Properties** \\(\cup,\,\cap,\, \circ,\, \star,\, \bar{A}\\)

## Pumping Lemma for RLs
Let \\(A\\) be a regular language. There must exist some \\(p \geq 1 \\) such that for all \\(w\in A\, :\, |w| \geq p\\) there is some split \\(w = xyz\\):

1. \\(xy^iz \in A\\) for all \\(i \geq 0\\)
2. \\(|y| \geq 0\\)
3. \\(|xy| \leq |p|\\)

This is a necessary but not sufficient condition to be a regular language!

## Non-regular Languages
- \\(0^n1^n\, |\, n\geq 0 \\) : cannot pump \\(0^P1^P\\)
- \\( o^i1^j |\, i > j \\) : cannot pump \\(0^{P+1}1^P\\)

# Context Free Languages
A Language is Context Free if and only if it is recognized by a PDA or generated by a CFG. All regular languages are context free but not all context free languages are regular! Every DFA is a PDA that ignores its stack.

## PDA
Think NFA but with a stack. \\(P = (Q, \Sigma, \Gamma, \delta, q_0, F)\\)

## CFG
\\( G = (V, \Sigma, R, S) \\). Grammars *derive* strings. Ambiguity: can have multiple parse trees for a single grammar!

- \\(V\\) are VARIABLES and disjoint from the set of terminals
- \\(\Sigma\\) are the terminals
- \\(R\, :\, V \times (V \cup \Sigma)^*\\) are production rules

## PDA & CFG Equivalence
Construct a PDA from a CFG G with the same language:

- PDA P with input w. Push sentinel \$, then S
- Loop
    - if top of stack is a var \\(S\in V) pop it & nondeterministically choose a rule for S. Push the RHS of rule in reverse order on to the stack
    - if top of stack is a terminal, pop then match with next input symbol. If equivalent, continue, else *reject*
    - if top of stack is \$ and input is empty then enter accept state
<!--\vfill\columnbreak-->
Construct a CFG from a PDA P:

- Grammar G has variables \\(A_{pq}\\) for all \\(p,q\in Q\\)
- \\(A_{pq}\\) will be able to derive exactly those strings which can send state p with empty stack to state q with empty stack
- \\(S = A_{q_0q_{acc}}\\) : anything that sends from start to end with empty stack
- Rules have two options:
    - the first push char must be the last pop char: \\(A_{pq} \to aA_{rs}b\\) where r is the state after p and s is the last state before q and a is the input read at the first move and b the input read at the last move.
    -If the stack is emptied before q then we have \\( A_{pq} \to A_{pr}A_{rq} \\) where r is the state when the stack becomes empty.

CFG to PDA generalized conversion:

- \\(q_0\, \epsilon,\epsilon,\to S\$\, q_{loop}\\)
- from \\(q_{loop}\; LHS(r)\to RHS(r)\; q_{loop}\\) for \\(r \in R\\)
- \\(q_{loop} \epsilon, \$ \to \epsilon\; q_{accept}\\)

## Closure Properties
\\(\cup,A^* ,\circ\\) and also the following lemma: if \\(C\\) is a CFL and \\(R\\) is a regular language then \\(C\cap R\\) is a CFL. Corollary: if \\(R\\) is a regular language and \\(A\cap R\\) is a non-CFL then \\(A\\) is a non-CFL.

## Pumping Lemma for CFLs
Let \\(A\\) be a context free language. There must exist some \\(p \geq 1 \\) such that for all \\(w\in A\, :\, |w| \geq p\\) there is some split \\(w = uvxyz\\):

1. \\( uv^ixy^iz \in A \\) for all \\(i\geq 0\\)
* \\( |vy| \geq 1 \\) v and y cannot both be \\(\epsilon\\)
* \\( |vxy| \leq p\\)

This is due to the pigeonhole principle: for a sufficiently long parse tree for a CFG (height of tree greater than number of variables) *some* variable \\(R\\) must be repeated!
This is a necessary but not sufficient condition to be a CFL!

## Non-Context Free Languages
Can prove a language is not context free either by the pumping lemma or the closure properties.

- \\(\{ a^nb^nc^n\, |\, n \geq 0 \}\\) cannot pump when \\(n = p\\)
- \\(\{ ww\, |\, w\in \{0,1\}^* \}\\) cannot pump string \\(w = 0^P1^P0^P1^P\\)
- \\(\{ w\in \{a,b,c,d\}^* \}\\) where \\(\#as = \#bs, \#cs = \#ds\\) - proved through lemma with \\(\cap R = \{a^nb^nc^md^m|n,m\geq 0\}\\) \\(a^Pc^Pb^Pd^P\\)
- \\(\{ w\in \{a,b,c\}^* \}\\) where \\(\#as = \#bs = \#cs\\) - in textbook problem 2.18b
<!--\vfill\columnbreak-->
# Turing Machines
\\(M = (Q,\Sigma,\Gamma,\delta,q_0, q_{acc}, q_{rej})\\) Has a finite state control with infinite tape. Has read head, can move \\(L,R\\).

A configuration \\(uqv\\) states that the read head \\(q\in Q\\) of the machine is at the leftmost symbol of \\(v\\) where \\(u,v\in \Gamma^*\\) represent the contents of the tape.

A TM *accepts* on input if the sequence of configs from the start config, given by \\(\delta\\) reaches the accept state in some *finite number of steps*. A TM *rejects* on input if the sequence of configs from the start config, given by \\(\delta\\) reaches the reject state in some *finite number of steps*.

## Church-Turing Thesis
Turing-machines can compute *anything* that can be computed - we define "what can be computed" as "what can be computed by a Turing-machine"

## Recognizability
A TM *recognizes* a language if it

1. accepts \\(\forall w\in L\\)
2. rejects **or** loops \\(\forall w\notin L\\).

Recognizable languages are closed under: \\(\cup,\cap,A^*,\circ\\). These are also known as "recursively-enumerable" languages.

## Decidability
A TM *decides* a language if it

1. accepts \\(\forall w\in L\\)
2. rejects \\(\forall w\notin L\\) and *does not loop*

Decidable languages are closed under: \\(\cup, \circ, A^*, \cap,\bar{A}\\)

## Equivalent Variants

- K-Tape Turing machines - can be emulated with a single tape turing machine by putting all k tapes on the single tape with dividers, etc
- Nondeterministic Turing Machines - can be emulated with a 3-tape turing machine: 1st tape input, 2nd tape simulation, 3rd tape address (think BFS of the computation tree). An NTM accepts if some thread reaches the accept state. An NTM rejects if all threads terminate and reject. An NTM loops in any other case.

Proof of NTM and TM equivalence: 3-tape TM as above. If any simulated branch accepts then accept. If all locations of some length/depth reject then reject.

Why BFS instead of DFS for a NTM? Because DFS may go forever down a branch, and BFS ensures that the NTM will visit every node in the tree until it encounters and accepting configuration!

<!--\newpage-->
## Enumerators
An enumerator is a special type of TM with two tapes: one work tape (same as a normal tape) and one write-only printer (or output tape). Writes strings separated by a # to output tape. \\(L(E) = \{w\, :\, E\; outputs\; w\; eventually\}\\). A language is **enumerable** if it is the language of some enumerator. Enumerators do not necessarily halt.


## Enumerabilty, Recognizability
A language is *enumerable* \\(\Leftrightarrow\\) it is *recognizable*.

Proof: enumerable \\(\Rightarrow\\) recognizable. Given E for language, build a TM M that recognizes as follows: run E and if the input \\(w\\) ever appears on its ouput tape then accept. If E halts reject. If \\(w\in L\\) then E eventually outputs w. If \\(w\notin L\\) then E never outputs w, no M either loops or rejects.

Proof: recognizable \\(\Rightarrow\\) enumerable. Given TM M that recognizes L build E. Consider strings in \\(\Sigma^*\\) in some order: \\(w_1=\epsilon,w_2=0,\dotsc\\). For \\(i=1,2,\dotsc\\) for each string \\(w_j,1\leq j\leq i\\) run M for up to i steps. If M ever accepts then print \\(w_j\\).

For any string \\(w\in \Sigma^*\\) \\(E\\) eventually runs M for any desired finite number of steps.

# Reductions
Quick fact: the set of all languages is **not** countably infinite. See diagonalization proof notes

**Theorem**: \\(A\\) is decidable \\(\Leftrightarrow A,\overline{A}\\) are recognizable. This is why \\(\overline{A}_{TM}\\) is undecidable. Proof: run both recognizers in parallel to build decider

**Turing reduction** \\(C\leq_T D\\). If \\(C\\) is undecidable then so too is \\(D\\), if \\(D\\) is decidable then so too is \\(C\\).

**Computable Functions**: a function\\(f\\) is computable if there is a TM that, on every \\(w\in\Sigma^*\\) halts with just \\(f(w)\\) on its tape.

**Mapping reduction** notes: if \\(A\leq_M B\\) then mapping function \\(f\\) has to fulfill: \\(w\in A \Leftrightarrow f(w)\in B\\). This converts an instance of \\(A\\) into an instance of \\(B\\). This also means that \\(f\\) converts an instance of \\(\overline{A}\\) to an instance of \\(\overline{B}\\)!

If \\(B\\) above is recognizable/decidable then so too is \\(A\\). If \\(A\\) is unrecognizable/undecidable then so too is \\(B\\). However: **turing reductions are useless for proving unrecognizability!*

Reglangs < CFLs < Decidable < Recognizable < All langs
<!--\vfill\columnbreak-->
**Decidable**: \\(A_{DFA}\\), \\(E_{DFA}\\), \\(EQ_{DFA}\\), \\(A_{CFG},\\), \\(E_{CFG}\\), All CFLs

**Recog**: \\(A_{TM},HALT_{TM}\\), \\(\overline{E}_{TM}\\), \\(ALL_{CFG}\\), \\(EQ_{CFG}\\)

**Unrec**: \\(\overline{A}_{TM}\\), \\(E_{TM}\\), \\(EQ_{TM}\\), \\(\overline{EQ}_{TM}\\)

\\(A_{TM}\leq_M HALT_{TM}\\), \\(A_{TM}\leq_T E_{TM}\\), \\(E_{TM}\leq_M EQ_{TM}\\), \\(A_{TM}\leq_M \overline{E}_{TM}\\), \\(A_{TM}\leq_M EQ_{TM}\\)
\\(\overline{A}_{TM}\leq_M E_{TM} \leq_M EQ_{TM}\\)

Going from a smaller class to a larger class (recog to unrecog) is ok. The reverse isn't!
## Rice's Theorem
Let \\(P\in\mathcal{P}(\mathcal{P}(\Sigma^*))\\) be a non-trivial property of languages viewed as a set of languages. Assume there are decidable languages \\(Y\in P\\) and \\(N\notin P\\). \\(PROP-P_{TM} = \{<M> : L(M)\in P\}\\) - this is undecidable for any such \\(P\\)! This includes properties like 'regularity'.

Proof: Reduce from \\(A_{TM}\\). Define decider for \\(A_{TM}\\), where \\(M_{y/n}\\) are machines with the languages \\(Y,N\\) respectively: "On input \\(<M, w>\\)

1. Build a TM \\(M'\\): "On any input run \\(M\\) on \\(w\\). If it accepts run \\(M_y\\) on \\(w'\\), output its result. If it rejects run \\(M_n\\) on \\(w'\\) and output its result"
2. Run the decider for \\(PROP-P_{TM}\\) on \\(M'\\) and output its result"

## Proof Notes
\\(E_{TM}\leq_M EQ_{TM}\\): have \\(EQ_{TM}\\) decider run a comparison on input \\(M\\) and a machine with an empty lang!
** All decidable languages reduce to each other except \\(\Sigma^*,\emptyset\\).

**Busy Beaver**: \\(H_n = \{M : M\\) is TM, has \\(n\\) states and halts on \\(\epsilon\}\\)
**Busy Beaver**: \\(BB(n) = max_{M\in H_n}(\#\\) of steps for \\(M(\epsilon))\\) is uncomputable -- there is no TM that on input \\(n\\) halts with a number \\(\geq BB(n)\\) on its tape. Proof showed that were there a machine that could compute \\(BB(n)\\) where n was the number of states in some TM that \\(A_{TM}\\) would be decidable (run M for up to n steps, look at result).

**Interleaving trick**: For each 1,2,3... run \\(M\\) on the first NUM strings for up to NUM steps. If \\(M\\) ever accepts, BLAH.

**Computation Histories**: Sequence of configurations for \\(M\\) on \\(2\\) \\(C_1,C_2,...C_l\\) where \\(C_1\\) is the initial configuration, and each \\(C_i\\) follows from \\(C_{i-1}\\) legally according to the rules of \\(M\\). Accepting histories are where \\(C_l\\) is an accepting configuration, and rejecting histories are \\(C_l\\) as a rejecting configuration.

<!--\vfill\columnbreak-->
## Recursion Theorem

Let \\(M\\) be any TM computing a function \\(m:\Sigma^* * \Sigma^*\to \Sigma^*\\) which is machine * string to anything. There exists some machine \\(R\\) computing \\(r: \Sigma^*\to\Sigma^*\\) where \\(r(w) = m(<R>, w)\\) for all \\(w\\). In short: *we can write TMs that obtain their own descriptions*.

**Pf**: \\(A_{TM}\\) undecidable - assume decider \\(H\\). Decider \\(B\\) for the barber machine: "On input \\(<M, w>\\): obtain \\(<B>\\) via recursion thm. Run \\(H\\) on \\(<B, w>\\) and output the opposite result"

We have above a machine that outputs the opposite of what it is supposed to output, and this doesn't work! \\(B\\) here does the opposite of itself.

**Pf**: \\(MIN_{TM}\\) is unrecognizable. Assume for contradiction that \\(E\\) enumerates \\(MIN_{TM}\\). Consider \\(C\\): "On input \\(w\\): get \\(<C>\\) via recursion thm. Run \\(E\\) until it outputs some \\(<D>\\) that is longer than \\(<C>\\). Simulate \\(D\\) on \\(w\\)"

We have a direct contradiction here: \\(D\\) should be minimal, but \\(C\\) is shorter **and** is equivalent to \\(D\\)! Contradiction, \\(D\\) cannot then be minimal. \\(E\\) will eventually output such a \\(<D>\\) because \\(MIN_{TM}\\) is infinite.

**Thunk**: \\(T_{M,w} =\\) "Ignore input, and (1) clear tape and write \\(w\\) to it (2) run \\(M\\) on \\(w\\)"

**Replicating Machines**: \\(B=\\) "On input \\(<M>\\): compute and write \\(<T_{M,<M>}>\\) to tape, then halt".This machine outputs thunks that run a machine on its own description! \\(T_{B,<B>}\\) (created by running \\(B\\) on itself) replicates itself infinitely!

## Proof examples
\\(A_{TM}\\): proof via diagonalization: assume some \\(H\\) decides \\(A_{TM}\\). Build a TM \\(D\\) such that "on input \\(<M>\\) run \\(H\\) on \\(<M, <M>\\) and output the opposite answer'. This is a decider because \\(H\\) is a decider -- \\(D\\) accepts all machines that reject when given their own description. What happens when we run \\(D\\) on \\(<D>\\)? We get a contradiciton: \\(D\\) accepts \\(<D>\Leftrightarrow H\\) rejects \\(<D, <D>>\Leftrightarrow D\\) rejects \\(<D>\\).

**Diagonalization**: in essence construct a new valid machine or sequence that contradicts itself or the proof mechanism. Proving that languages are not countably infinite: Assume we can list all subsets of \\(\{0,1\}^* : S_1,S_2...\\). We can construct a new subset \\(S\\) that we've missed as follows: for each \\(i\in \mathcal{N}\\) if \\(w_i\notin S_i\\) then \\(w_i\in S\\). Clearly \\(S\subseteq \{0,1\}^*\\) but \\(\forall i : S\neq S_i\\). We have here a contradiction.

<!--\vfill\columnbreak-->

\\(ALL_{CFG} = \{ <G> : G\\) is a CFG and \\(L(G)=\Sigma^* \}\\). Proof: reduce from \\(A_{TM}\\), design a CFG \\(G\\) that generates all strings iff \\(M\\) does not accept \\(w\\) otherwise do not generate the accepting configuration history for it. \\(G\\) generates all strings that a) don't start with \\(C_1\\) b) don't end with an accepting configuration or c) where some \\(C_i\\) does not follow legally from its prior. If \\(M\\) rejects \\(w\\) then there is a string that exists that \\(G\\) does not generate: the string beginning with \\(C_1\\), ending in an accepting configuration, and where each \\(C_i\\) is built legally upon its predecessor.

## Reductions 'relative to...'
'Y decidable relative to X means that Y can be decided given an Oracle for X -- meaning that \\(M^X\\) could decide Y given an oracle for X.
Not every language is decidable or recognizable relative to \\(A_{TM}\\)! Take the language \\(A_{TM}' = \{ <M^\bullet, w> : M^\bullet\\) is an oracle TM and \\(M^{A_{TM}}\\) accepts \\(w\}\\). This is not decidable relative to \\(A_{TM}\\) -- see the proof for \\(A_{TM}\\) undecidability and 'relativize' by giving all machines an \\(A_{TM}\\) oracle!

# Time Complexity

Currently \\(P \subset NP\\), NPC is the intersection of NP and NP-Hard, NP-Hard is not all in NP

\\(TIME(t(n))\\) is the collection of languages that are decidable by an \\(O(t(n))\\) time turing machine

\\(P\\) is the class of languages that are decidable in polynomial time by a deterministic, single-tape TM; \\(P = \bigcup_{k} TIME(n^k)\\)

\\(NTIME(t(n))\\) is the collection of languages that are decidable by an \\(O(t(n))\\) time nondeterministic TM

\\(NP\\) is the class of languages that are decidable in polynomial time by a nondeterministic TM. \\(NP = \bigcup_{k} NTIME(t(n))\\)
Alternatively: the class of languages that can be *verified* in polynomial time (given an input and a certificate/finding/guessing an answer and checking). NP is closed under \\(\circ, \cap, \cup\\)


Let \\(t(n)\geq n\\). Every multitape turing machine with run-time \\(t(n)\\) has an equivalent single-tape turing machine with run-time \\(O(t^2(n))\\)


Every nondeterministic turing machine has an equivalent \\(2^{O(t(n))}\\) single-tape turing machine (exponential time!)


A language is NP-Complete if it is a) in NP and b) at least as hard as every other problem in NP; NP-Hard, so  \\(SAT\leq_P L\\). Note: a poly-time reduction has all the same decidability properties as a mapping reduction because it satisfies the criteria (assuming \\(A\leq_P B\\)) \\(w\in A \Leftrightarrow f(w)\in B\\)


Example languages in P: all CFLs, PATH (is there a path in a graph from \\(s\to t\\)), RELPRIME (are x,y relatively prime? e.g. largest num that divides both is 1), \\(A_{DFA}, E_{DFA}. EQ_{DFA}\\)


Example NP-Hard (but not NPC) languages: \\(HALT_{TM}\\)


Example NP-Complete languages: 3SAT, SAT, 3CNF, CLIQUE, VERTEX-COVER, HAMPATH, SUBSETSUM


Proving things are NP-Complete: use variable, clause gadgets when reducing from 3CNF to your new language!


NP-Complete is closed under: \\(\cup, \circ\\) but NOT intersection! Take \\(L\in NP\\): create \\(L_0 = \{0w | w\in L\}\\) and \\(L_1 = \{1w | w\in L\}\\). \\(L_1\cap L_2 = \emptyset\\)

**For run-time analysis**: if you use other machines that have a run-time, list it! if it's polynomial then say its runtime is \\(p^a\\) so you can do things like "This new machine runs in time \\(O(n^{max(a, b)})\\) as it runs two sub-machines with run times \\(p^a, p^b\\) respectively so its run-time is bounded by theirs"
